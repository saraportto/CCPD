{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcrRKkwhFNJ8"
      },
      "source": [
        "# Ejercicio 4 - Evitar conflictos en acceso a bancos de memoria compartida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJVT_5hXFNKA"
      },
      "source": [
        "Partiendo del fichero modificado en el apartado anterior:\n",
        "\n",
        "* Copiar el kernel `tile_traspose()` en `tile_transpose2()`\n",
        "* Modificar el kernel `tile_transpose2()` para evitar conflictos en acceso a bancos de memoria compartida\n",
        "* Comparar las prestaciones de los tres kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-11T15:46:45.923571Z",
          "iopub.status.busy": "2025-05-11T15:46:45.923106Z",
          "iopub.status.idle": "2025-05-11T15:46:53.113345Z",
          "shell.execute_reply": "2025-05-11T15:46:53.112650Z",
          "shell.execute_reply.started": "2025-05-11T15:46:45.923546Z"
        },
        "id": "74QUWN4pFNKB",
        "outputId": "08cfd3ce-4d2d-421b-f272-69a7290e7a1a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (0.60.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Ejecutar en Google Colab\n",
        "!pip install numpy matplotlib scikit-image numba cython setuptools\n",
        "\n",
        "### EVITAR ERRORES\n",
        "\n",
        "!uv pip install -q --system numba-cuda==0.4.0\n",
        "\n",
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-11T15:46:53.114971Z",
          "iopub.status.busy": "2025-05-11T15:46:53.114744Z",
          "iopub.status.idle": "2025-05-11T15:47:29.690649Z",
          "shell.execute_reply": "2025-05-11T15:47:29.689982Z",
          "shell.execute_reply.started": "2025-05-11T15:46:53.114949Z"
        },
        "id": "NViDnx7jFNKD",
        "outputId": "e5270701-2821-48ee-b952-9c4dc6ab8e00",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tiempo en CPU:\n",
            "110 ns ± 22.4 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
            "\n",
            "Tiempo en GPU - NO optimizado:\n",
            "1.65 ms ± 38.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "\n",
            "Tiempo en GPU - OPTIMIZADO:\n",
            "1.77 ms ± 9.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "\n",
            "Tiempo en GPU - OPTIMIZADO + sin conflictos mem compartida:\n",
            "1.08 ms ± 8.44 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda, types as numba_types\n",
        "import numpy as np\n",
        "\n",
        "n = 4096*4096 # 16M elementos a procesar\n",
        "\n",
        "# KERNEL: SIN MEMORIA COMPARTIDA + acceso NO COALESCENTE\n",
        "@cuda.jit\n",
        "def transpose(a, transposed):\n",
        "    x, y = cuda.grid(2)\n",
        "    transposed[x][y] = a[y][x]\n",
        "\n",
        "\n",
        "# KERNEL: MEMORIA COMPARTIDA + acceso COALESCENTE\n",
        "@cuda.jit\n",
        "def tile_transpose(a, transposed):\n",
        "    # bloques 32x32\n",
        "\n",
        "    # ARRAY en memoria compartida (accesible por todos los hilos de un mismo bloque)\n",
        "    tile = cuda.shared.array(shape=(32, 32), dtype = numba_types.float32) # reserva espacio\n",
        "\n",
        "    # ÍNDICES globales\n",
        "    a_row, a_col = cuda.grid(2) # x, y\n",
        "\n",
        "    # CARGAR de mem GLOBAL a mem COMPARTIDA, con índices locales\n",
        "    tile[cuda.threadIdx.y, cuda.threadIdx.x] = a[a_row, a_col]  # warps se acceden por columna (columna lee fila de a)\n",
        "\n",
        "    # ESPERA a que todos los hilos del bloque actualicen la escritura\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    t_row, t_col = cuda.grid(2) # índices globales del bloque\n",
        "\n",
        "    # ESCRIBIR de mem COMPARTIDA a mem GLOBAL, transponiendo\n",
        "    transposed[t_row, t_col] = tile[cuda.threadIdx.x, cuda.threadIdx.y]\n",
        "\n",
        "\n",
        "# KERNEL: SIN CONFLICTOS en MEMORIA COMPARTIDA + acceso COALESCENTE\n",
        "@cuda.jit\n",
        "def tile_transpose2(a, transposed):\n",
        "    # bloques 32x32\n",
        "\n",
        "    # ARRAY en memoria compartida (accesible por todos los hilos de un mismo bloque)\n",
        "    tile = cuda.shared.array(shape=(32, 33), dtype = numba_types.float32) # reserva espacio\n",
        "\n",
        "    # ÍNDICES globales\n",
        "    a_row, a_col = cuda.grid(2) # x, y\n",
        "\n",
        "    # CARGAR de mem GLOBAL a mem COMPARTIDA, con índices locales\n",
        "    tile[cuda.threadIdx.y, cuda.threadIdx.x] = a[a_row, a_col]  # warps se acceden por columna (columna lee fila de a)\n",
        "\n",
        "    # ESPERA a que todos los hilos del bloque actualicen la escritura\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    t_row, t_col = cuda.grid(2) # índices globales del bloque\n",
        "\n",
        "    # ESCRIBIR de mem COMPARTIDA a mem GLOBAL, transponiendo\n",
        "    transposed[t_row, t_col] = tile[cuda.threadIdx.x, cuda.threadIdx.y]\n",
        "\n",
        "\n",
        "# PARÁMETROS\n",
        "threads_per_block = (32, 32) # 2D blocks\n",
        "blocks = (128, 128) #2D grid\n",
        "\n",
        "# VARIABLES CPU\n",
        "h_a = np.arange(n).reshape((4096,4096)).astype(np.float32)\n",
        "\n",
        "# VARIABLES GPU\n",
        "d_a = cuda.to_device(h_a)\n",
        "d_transposed = cuda.device_array(shape=(4096,4096), dtype=np.float32) # guarda espacio\n",
        "\n",
        "# LANZA KERNEL transpose\n",
        "transpose[blocks, threads_per_block](d_a, d_transposed)\n",
        "result_transpose = d_transposed.copy_to_host() # result a CPU\n",
        "\n",
        "# LANZA KERNEL tile_transpose (optimización)\n",
        "tile_transpose[blocks, threads_per_block](d_a, d_transposed)\n",
        "result_tile_transpose = d_transposed.copy_to_host() # result a CPU\n",
        "\n",
        "# LANZA KERNEL tile_transpose (optimización + sin conflictos)\n",
        "tile_transpose2[blocks, threads_per_block](d_a, d_transposed)\n",
        "result_tile_transpose2 = d_transposed.copy_to_host() # result a CPU\n",
        "\n",
        "# RESULTADO ESPERADO\n",
        "expected = h_a.T\n",
        "\n",
        "# COMPROBACIÓN\n",
        "np.testing.assert_equal(result_transpose, expected)\n",
        "np.testing.assert_equal(result_tile_transpose, expected)\n",
        "np.testing.assert_equal(result_tile_transpose2, result_tile_transpose)\n",
        "\n",
        "# MEDICIÓN\n",
        "# cpu\n",
        "print(\"\\nTiempo en CPU:\")\n",
        "%timeit h_a.T\n",
        "\n",
        "# gpu no optimizado\n",
        "print(\"\\nTiempo en GPU - NO optimizado:\")\n",
        "%timeit transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()\n",
        "\n",
        "# gpu optimizado\n",
        "print(\"\\nTiempo en GPU - OPTIMIZADO:\")\n",
        "%timeit tile_transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()\n",
        "\n",
        "# gpu optimizado + sin conflictos\n",
        "print(\"\\nTiempo en GPU - OPTIMIZADO + sin conflictos mem compartida:\")\n",
        "%timeit tile_transpose2[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
