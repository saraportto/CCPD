{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ejercicio 4 - Evitar conflictos en acceso a bancos de memoria compartida","metadata":{}},{"cell_type":"markdown","source":"Partiendo del fichero modificado en el apartado anterior:\n\n* Copiar el kernel `tile_traspose()` en `tile_transpose2()`\n* Modificar el kernel `tile_transpose2()` para evitar conflictos en acceso a bancos de memoria compartida\n* Comparar las prestaciones de los tres kernels","metadata":{}},{"cell_type":"code","source":"# Ejecutar en Google Colab\n!pip install numpy matplotlib scikit-image numba cython setuptools\n\n### EVITAR ERRORES\n\n!uv pip install -q --system numba-cuda==0.4.0\n\nfrom numba import config\nconfig.CUDA_ENABLE_PYNVJITLINK = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:46:45.923106Z","iopub.execute_input":"2025-05-11T15:46:45.923571Z","iopub.status.idle":"2025-05-11T15:46:53.113345Z","shell.execute_reply.started":"2025-05-11T15:46:45.923546Z","shell.execute_reply":"2025-05-11T15:46:53.112650Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (0.60.0)\nRequirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.2)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.1.10)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from numba import cuda, types as numba_types\nimport numpy as np\n\nn = 4096*4096 # 16M elementos a procesar\n\n# KERNEL: SIN MEMORIA COMPARTIDA + acceso NO COALESCENTE\n@cuda.jit\ndef transpose(a, transposed):\n    x, y = cuda.grid(2)\n    transposed[x][y] = a[y][x]\n\n\n# KERNEL: MEMORIA COMPARTIDA + acceso COALESCENTE\n@cuda.jit\ndef tile_transpose(a, transposed):\n    # bloques 32x32\n\n    # ARRAY en memoria compartida (accesible por todos los hilos de un mismo bloque)\n    tile = cuda.shared.array(shape=(32, 32), dtype = numba_types.float32) # reserva espacio\n\n    # ÍNDICES globales\n    a_row, a_col = cuda.grid(2)\n\n    # CARGAR de mem GLOBAL a mem COMPARTIDA, con índices locales\n    tile[cuda.threadIdx.x, cuda.threadIdx.y] = a[a_row, a_col]  # warps se acceden por columna (columna lee fila de a)        \n    \n    # ESPERA a que todos los hilos del bloque actualicen la escritura\n    cuda.syncthreads()\n\n    # ESCRIBIR de mem COMPARTIDA a mem GLOBAL, transponiendo\n    transposed[a_col, a_row] = tile[cuda.threadIdx.x, cuda.threadIdx.y]\n\n\n# KERNEL: SIN CONFLICTOS en MEMORIA COMPARTIDA + acceso COALESCENTE\n@cuda.jit\ndef tile_transpose2(a, transposed):\n    # bloques 32x32\n\n    # ARRAY en memoria compartida (accesible por todos los hilos de un mismo bloque)\n    tile = cuda.shared.array(shape=(32, 32), dtype = numba_types.float32) # reserva espacio\n\n    # ÍNDICES globales\n    a_row, a_col = cuda.grid(2)\n\n    # CARGAR de mem GLOBAL a mem COMPARTIDA, con índices locales\n    tile[cuda.threadIdx.x, cuda.threadIdx.y] = a[a_row, a_col]  # warps se acceden por columna (columna lee fila de a)        \n    \n    # ESPERA a que todos los hilos del bloque actualicen la escritura\n    cuda.syncthreads()\n\n    # ESCRIBIR de mem COMPARTIDA a mem GLOBAL, transponiendo\n    transposed[a_col, a_row] = tile[cuda.threadIdx.x, cuda.threadIdx.y]\n\n\n# KERNEL: MEMORIA COMPARTIDA + acceso COALESCENTE\n@cuda.jit\ndef tile_transpose2(a, transposed):\n    # bloques 32x32\n\n    # ARRAY en memoria compartida (accesible por todos los hilos de un mismo bloque)\n    tile = cuda.shared.array(shape=(32, 33), dtype = numba_types.float32) # reserva espacio\n\n    # ÍNDICES globales\n    a_row, a_col = cuda.grid(2)\n\n    # CARGAR de mem GLOBAL a mem COMPARTIDA, con índices locales\n    tile[cuda.threadIdx.x, cuda.threadIdx.y] = a[a_row, a_col]  # warps se acceden por columna (columna lee fila de a)        \n    \n    # ESPERA a que todos los hilos del bloque actualicen la escritura\n    cuda.syncthreads()\n\n    # ESCRIBIR de mem COMPARTIDA a mem GLOBAL, transponiendo\n    transposed[a_col, a_row] = tile[cuda.threadIdx.x, cuda.threadIdx.y]\n\n\n# PARÁMETROS\nthreads_per_block = (32, 32) # 2D blocks\nblocks = (128, 128) #2D grid\n\n# VARIABLES CPU\nh_a = np.arange(n).reshape((4096,4096)).astype(np.float32)\n\n# VARIABLES GPU\nd_a = cuda.to_device(h_a)\nd_transposed = cuda.device_array(shape=(4096,4096), dtype=np.float32) # guarda espacio\n\n# LANZA KERNEL transpose\ntranspose[blocks, threads_per_block](d_a, d_transposed)\nresult_transpose = d_transposed.copy_to_host() # result a CPU\n\n# LANZA KERNEL tile_transpose (optimización)\ntile_transpose[blocks, threads_per_block](d_a, d_transposed)\nresult_tile_transpose = d_transposed.copy_to_host() # result a CPU\n\n# LANZA KERNEL tile_transpose (optimización + sin conflictos)\ntile_transpose2[blocks, threads_per_block](d_a, d_transposed)\nresult_tile_transpose2 = d_transposed.copy_to_host() # result a CPU\n\n# RESULTADO ESPERADO\nexpected = h_a.T\n\n# COMPROBACIÓN\nnp.testing.assert_equal(result_transpose, expected)\nnp.testing.assert_equal(result_tile_transpose, expected)\nnp.testing.assert_equal(result_tile_transpose2, result_tile_transpose)\n\n# MEDICIÓN\n# cpu\nprint(\"\\nTiempo en CPU:\")\n%timeit h_a.T\n\n# gpu no optimizado\nprint(\"\\nTiempo en GPU - NO optimizado:\")\n%timeit transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()\n\n# gpu optimizado\nprint(\"\\nTiempo en GPU - OPTIMIZADO:\")\n%timeit tile_transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()\n\n# gpu optimizado + sin conflictos\nprint(\"\\nTiempo en GPU - OPTIMIZADO + sin conflictos mem compartida:\")\n%timeit tile_transpose2[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:46:53.114744Z","iopub.execute_input":"2025-05-11T15:46:53.114971Z","iopub.status.idle":"2025-05-11T15:47:29.690649Z","shell.execute_reply.started":"2025-05-11T15:46:53.114949Z","shell.execute_reply":"2025-05-11T15:47:29.689982Z"}},"outputs":[{"name":"stdout","text":"\nTiempo en CPU:\n108 ns ± 0.202 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n\nTiempo en GPU - NO optimizado:\n1.56 ms ± 16.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\nTiempo en GPU - OPTIMIZADO:\n1.7 ms ± 4.12 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\nTiempo en GPU - OPTIMIZADO + sin conflictos mem compartida:\n1.03 ms ± 2.97 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n","output_type":"stream"}],"execution_count":2}]}