{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120f22b2",
   "metadata": {},
   "source": [
    "## Tema 11: Introducción a NVidia CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735b711",
   "metadata": {},
   "source": [
    "## C - Kernels en CUDA\n",
    "\n",
    "__Primer Kernel CUDA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "# Kernels decorados con `@cuda.jit` no devuelven valores\n",
    "# No es necesaria signatura de tipos\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    idx = cuda.grid(1)\n",
    "        # 1 = grid unidimensional\n",
    "        # cuda.grid(1) = cuda.threadIdx.x + cuda.blockIdx.x*cuda.blockDim.x\n",
    "    out[idx] = x[idx] + y[idx]\n",
    "\n",
    "\n",
    "n = 4096\n",
    "h_x = np.arange(n).astype(np.float32)  # [0.0 ... 4095.0] \n",
    "h_y = np.ones_like(h_x)              # [1.0 ... 1.0] \n",
    "\n",
    "d_x = cuda.to_device(h_x) \n",
    "d_y = cuda.to_device(h_y) \n",
    "d_out = cuda.device_array_like(d_x) \n",
    "\n",
    "# Necesitamos un hilo para cada elemento (4096)\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 32\n",
    "\n",
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "cuda.synchronize() # Esto sería innecesario\n",
    "print(d_out.copy_to_host().astype(np.int16)) # Resultado: [1...4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caea9e3-3c8b-4a78-86de-88b9ab92539d",
   "metadata": {},
   "source": [
    "__Ejercicio 1: crear un Kernel a partir de una función__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b594c10-80f6-4eac-9ff8-9269450dfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 16384\n",
    "def h_square(a):\n",
    "    return a**2\n",
    "\n",
    "# TODO: implementar un kernel d_square()\n",
    "\n",
    "a = np.arange(n, dtype=np.float32) \n",
    "# TODO: crear vector d_a y copiar al kernel\n",
    "# TODO: crear vector en GPU para obtener la salida\n",
    "\n",
    "# TODO: modificar estos valores e invocar kernel\n",
    "blocks = 0\n",
    "threads = 0\n",
    "\n",
    "# TODO: Launch as a kernel with an appropriate execution configuration\n",
    "out = h_square(a)\n",
    "\n",
    "out_aux = a**2\n",
    "np.testing.assert_almost_equal(out, out_aux)\n",
    "# TODO: reemplazar out_aux con lo obtenido en el kernel (usar .copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ace381-47fb-4576-815a-5fe3ca5544fc",
   "metadata": {},
   "source": [
    "## D - Uso de stride en Kernels CUDA\n",
    "\n",
    "__Sin stride__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f123ee-e369-4aee-aa7e-bc502476b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    idx = cuda.grid(1)\n",
    "    out[idx] = x[idx] + y[idx]\n",
    "\n",
    "n = 4096\n",
    "h_x = np.arange(n).astype(np.float32)  \n",
    "h_y = np.ones_like(h_x)              \n",
    "\n",
    "d_x = cuda.to_device(h_x) \n",
    "d_y = cuda.to_device(h_y) \n",
    "d_out = cuda.device_array_like(d_x) \n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 32\n",
    "\n",
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "d_out.copy_to_host().astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74f6e5-440e-44fb-8de1-5c4f90a78e6d",
   "metadata": {},
   "source": [
    "__Con stride__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a552a98-512c-4d55-b28e-2ac13105b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]\n",
    "\n",
    "\n",
    "n = 125000\n",
    "h_x = np.arange(n).astype(np.float32) \n",
    "h_y = np.ones_like(h_x)         \n",
    "\n",
    "d_x = cuda.to_device(h_x) \n",
    "d_y = cuda.to_device(h_y) \n",
    "d_out = cuda.device_array_like(d_x) \n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 56\n",
    "\n",
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "d_out.copy_to_host().astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f07d4c-055f-4f8a-a5eb-97953bdceb02",
   "metadata": {},
   "source": [
    "__Ejercicio 2: kernel CUDA con stride__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1fe4a5-ac6d-4cc1-85a9-ac886cdb2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import hypot\n",
    "from numba import cuda\n",
    "\n",
    "def cpu_hypot(a,b):\n",
    "    return np.hypot(a,b)\n",
    "\n",
    "# TODO: implementar esta función\n",
    "# usando stride\n",
    "def gpu_hypot_stride(a, b, c):\n",
    "    None\n",
    "\n",
    "# No modificar a partir de aquí\n",
    "n = 1000000\n",
    "h_a = np.random.uniform(-12, 12, n).astype(np.float32)\n",
    "h_b = np.random.uniform(-12, 12, n).astype(np.float32)\n",
    "d_a = cuda.to_device(h_a)\n",
    "d_b = cuda.to_device(h_b)\n",
    "d_c = cuda.device_array_like(d_b)\n",
    "\n",
    "blocks = 128\n",
    "threads_per_block = 64\n",
    "gpu_hypot_stride[blocks, threads_per_block](d_a, d_b, d_c)\n",
    "np.testing.assert_almost_equal(np.hypot(h_a, h_b), d_c.copy_to_host(), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41645142-0a22-4efd-909e-29d11024c183",
   "metadata": {},
   "source": [
    "## E - Operaciones atómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fb7d4-0805-4825-a30e-5510f87c42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def thread_counter_race_condition(global_counter):\n",
    "    global_counter[0] += 1  # Mal\n",
    "    \n",
    "@cuda.jit\n",
    "def thread_counter_safe(global_counter):\n",
    "    cuda.atomic.add(global_counter, 0, 1) \n",
    "\n",
    "# Esto no funciona bien\n",
    "global_counter = cuda.to_device(np.array([0], dtype=np.float32))\n",
    "thread_counter_race_condition[64, 64](global_counter)\n",
    "print('Debería dar %d:' % (64*64), global_counter.copy_to_host().astype(np.int16))\n",
    "\n",
    "# Esto sí funciona bien\n",
    "global_counter = cuda.to_device(np.array([0], dtype=np.float32))\n",
    "thread_counter_safe[64, 64](global_counter)\n",
    "print('Debería dar %d:' % (64*64), global_counter.copy_to_host().astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dabaee-68df-45db-9154-d42c1ea63b0b",
   "metadata": {},
   "source": [
    "## F - Kernels bidimensionales y tridimensionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fca5f-d948-440e-8812-15e4f673060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def get_2D_indices(A):\n",
    "    x, y = cuda.grid(2) # Obtenemos las dos dimensiones\n",
    "    # Equivalente a:\n",
    "    # x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    # y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    \n",
    "    # Escribimos índice x + '.' + índice y\n",
    "    A[x][y] = x + y / 10\n",
    "\n",
    "d_A = cuda.device_array(shape=(4,4), dtype=np.float32)\n",
    "    # Matriz 4x4 en la GPU\n",
    "\n",
    "blocks = (2, 2) # Grid = 2x2 bloques\n",
    "threads_per_block = (2, 2) # Bloque = 2x2 threads\n",
    "\n",
    "get_2D_indices[blocks, threads_per_block](d_A)\n",
    "np.set_printoptions(precision=1, suppress=True)\n",
    "print(d_A.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6a442-8e2d-49b8-ba03-6c4b561bf49e",
   "metadata": {},
   "source": [
    "__Kernel bidimensional: suma de matrices__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5855cd-8325-4bd9-9da8-2b3b332cd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit  # Adjust block size as needed\n",
    "def add_matrices(a, b, c):\n",
    "    i, j = cuda.grid(2)  # Get thread indices in two dimensions (row, column)\n",
    "    c[i, j] = a[i, j] + b[i, j]\n",
    "\n",
    "# Example usage\n",
    "rows = 4096\n",
    "cols = 4096\n",
    "\n",
    "h_a = np.random.rand(rows, cols).astype(np.float32)  # Allocate matrices on CPU\n",
    "h_b = np.random.rand(rows, cols).astype(np.float32)\n",
    "d_a = cuda.to_device(h_a)  # Transfer matrices to GPU\n",
    "d_b = cuda.to_device(h_b)\n",
    "d_c = cuda.device_array_like(d_b)\n",
    "\n",
    "threads_per_block = (32, 32)\n",
    "blocks = (128, 128)\n",
    "\n",
    "add_matrices[blocks, threads_per_block](d_a, d_b, d_c)  # Launch kernel with appropriate grid size\n",
    "\n",
    "h_c = d_c.copy_to_host()\n",
    "\n",
    "np.testing.assert_almost_equal(h_c, h_a+h_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0cf42-33bf-4a7c-82e5-c9d004569c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit c_aux= (h_a + h_b)\n",
    "%timeit add_matrices[blocks, threads_per_block](d_a, d_b, d_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73660465-f328-4cb5-bb7d-8b03562eceaa",
   "metadata": {},
   "source": [
    "__Ejercicio 3: kernel bidimensional para procesar una imagen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96848d22-78af-40fe-a951-f1c90378c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesitamos skimage\n",
    "# Instalar con\n",
    "#       conda install scikit-image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, color\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def blur(input, output):\n",
    "    x, y = cuda.grid(2)\n",
    "    if x>0 and y>0 and x<(input.shape[0]-1) and y<(input.shape[1]-1):\n",
    "        output[x][y] = 0.25*(input[x-1][y]+input[x+1][y]+input[x][y-1]+input[x][y+1])\n",
    "    else:\n",
    "        output[x][y] = input [x][y]\n",
    "\n",
    "# TODO: definir tamaño de grid y de bloque\n",
    "num_cycles = 100\n",
    "\n",
    "astronaut = (255.-color.rgb2gray(data.astronaut()))/255.0\n",
    "print(\"Image size: \",astronaut.shape)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(astronaut,  cmap='Greys')\n",
    "\n",
    "# TODO: datos a GPU (duplicar imagen)\n",
    "\n",
    "# TODO: ejecutar num_cycles veces un el kernel blur\n",
    "\n",
    "# TODO: copiar imagen desenfocada al host\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(astronaut_blurred, cmap='Greys')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
